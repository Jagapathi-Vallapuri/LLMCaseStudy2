{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM CASE STUDY\n",
    "# NAMES: SOURABH R KAKRANNAYA, Vallapuri Jagapathi\n",
    "# SRN: PES1UG22AM164, PES1UG22AM183"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INGESTION AND PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-11T07:55:54.801621Z",
     "iopub.status.busy": "2025-03-11T07:55:54.801253Z",
     "iopub.status.idle": "2025-03-11T07:56:04.926772Z",
     "shell.execute_reply": "2025-03-11T07:56:04.926117Z",
     "shell.execute_reply.started": "2025-03-11T07:55:54.801580Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import re\n",
    "import pdfplumber\n",
    "import pandas as pd\n",
    "from tabula import read_pdf  # Library used to extract tables from PDFs\n",
    "\n",
    "# Configure logging to display info-level messages\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Directory to save extracted text and tables\n",
    "output_dir = \"/kaggle/working/\"\n",
    "os.makedirs(output_dir, exist_ok=True)  # Ensure output directory exists\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Cleans extracted text by:\n",
    "    - Removing page numbers (e.g., \"Page X\")\n",
    "    - Removing non-ASCII characters\n",
    "    - Normalizing whitespace\n",
    "\n",
    "    Args:\n",
    "        text (str): Raw text extracted from PDF.\n",
    "\n",
    "    Returns:\n",
    "        str: Cleaned and formatted text.\n",
    "    \"\"\"\n",
    "    text = re.sub(r\"Page\\s?\\d+\", \"\", text)         # Remove \"Page X\"\n",
    "    text = re.sub(r\"[^\\x00-\\x7F]+\", \" \", text)     # Remove non-ASCII characters\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()       # Normalize whitespace\n",
    "    return text\n",
    "\n",
    "def extract_text(pdf_path):\n",
    "    \"\"\"\n",
    "    Extracts text content from a given PDF file.\n",
    "\n",
    "    Args:\n",
    "        pdf_path (str): Path to the input PDF file.\n",
    "\n",
    "    Returns:\n",
    "        str: Extracted text from the PDF with page numbers preserved.\n",
    "    \"\"\"\n",
    "    full_text = []\n",
    "    \n",
    "    with pdfplumber.open(pdf_path) as pdf:  # Open PDF file\n",
    "        for page_num, page in enumerate(pdf.pages, start=1):\n",
    "            page_text = page.extract_text() or \"\"  # Extract text from page\n",
    "            cleaned_text = clean_text(page_text)  # Clean extracted text\n",
    "            full_text.append(f\"Page {page_num}:\\n{cleaned_text}\\n\")  # Preserve page numbers\n",
    "    \n",
    "    return \"\\n\".join(full_text)  # Return extracted text as a single string\n",
    "\n",
    "def extract_tables(pdf_path):\n",
    "    \"\"\"\n",
    "    Extracts tables from a given PDF file and saves them as CSV files.\n",
    "\n",
    "    Args:\n",
    "        pdf_path (str): Path to the input PDF file.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of paths to the saved CSV files.\n",
    "    \"\"\"\n",
    "    table_paths = []\n",
    "\n",
    "    try:\n",
    "        tables = read_pdf(pdf_path, pages=\"all\", multiple_tables=True)  # Extract tables from all pages\n",
    "\n",
    "        if not tables:\n",
    "            logging.warning(f\"No tables found in {pdf_path}\")  # Log warning if no tables are found\n",
    "\n",
    "        for i, table in enumerate(tables):\n",
    "            # Generate output CSV file path\n",
    "            output_csv_path = os.path.join(output_dir, f\"{os.path.basename(pdf_path).replace('.pdf', '')}_table_{i + 1}.csv\")\n",
    "            table.to_csv(output_csv_path, index=False)  # Save table as CSV\n",
    "            table_paths.append(output_csv_path)  # Store CSV path\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error extracting tables from {pdf_path}: {e}\")  # Log error if table extraction fails\n",
    "\n",
    "    return table_paths  # Return list of extracted table paths\n",
    "\n",
    "def process_pdf(pdf_path):\n",
    "    \"\"\"\n",
    "    Main function to extract both text and tables from a PDF and save the results.\n",
    "\n",
    "    Args:\n",
    "        pdf_path (str): Path to the input PDF file.\n",
    "    \"\"\"\n",
    "    logging.info(f\"Processing: {pdf_path}\")  # Log start of processing\n",
    "\n",
    "    # Extract and save text\n",
    "    extracted_text = extract_text(pdf_path)\n",
    "    text_output_path = os.path.join(output_dir, f\"{os.path.basename(pdf_path).replace('.pdf', '')}.txt\")\n",
    "    \n",
    "    with open(text_output_path, \"w\", encoding=\"utf-8\") as text_file:\n",
    "        text_file.write(extracted_text)  # Save extracted text to file\n",
    "    \n",
    "    logging.info(f\"Text saved to: {text_output_path}\")  # Log saved text file\n",
    "\n",
    "    # Extract and save tables\n",
    "    table_paths = extract_tables(pdf_path)\n",
    "    logging.info(f\"Extracted {len(table_paths)} tables from: {pdf_path}\")  # Log table count\n",
    "\n",
    "    if not table_paths:\n",
    "        logging.warning(f\"No tables were extracted from {pdf_path}\")  # Log warning if no tables are extracted\n",
    "\n",
    "# Path to the input PDF file\n",
    "pdf_path = \"/kaggle/input/combined/combined_document_10.pdf\"\n",
    "\n",
    "# Run the PDF processing pipeline\n",
    "process_pdf(pdf_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG CONSTRUCTION:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T07:57:27.732342Z",
     "iopub.status.busy": "2025-03-11T07:57:27.731968Z",
     "iopub.status.idle": "2025-03-11T07:59:34.199012Z",
     "shell.execute_reply": "2025-03-11T07:59:34.198065Z",
     "shell.execute_reply.started": "2025-03-11T07:57:27.732304Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n",
      "  has_large_values = (abs_vals > 1e6).any()\n",
      "/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n",
      "  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n",
      "/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n",
      "  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n",
      "<ipython-input-7-fe8f426a46f9>:46: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\", model_kwargs={\"device\": device})\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75cb2cf66ce64f4cb4a5b074698a9e7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "572b278f03574dab9175780d0148635e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "192fe06e6ffa4d1891c9ba5175bc6bc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2aee35be849242b9a284947dad24441b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "474054cf0aaa47f1b48067c0549c26b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b122437ec080447089908b89410d6c75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52dbc023c91341eea1ba9e9e42c1a85c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21fe632825ef4cbeb2c2960fcff00bca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3fe04b7da1b4cba91b5e51d6d9cbfe7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a192b83d4b6d4b4bbf438c5dcdfa9a9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dd68d490b1343a682793ca837789106",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0917aaa189f841b2a81e43d8e411ccfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/601 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b00d123d84c64269bde29ab6d757bf97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6b0172299164ddf9623f1d16460a069",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a8d8ae1b34d4eea90cb87310988180e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00003.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f94ee66559348faaaa72207e8190c39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b7b2f4b7913419a8ac7bf59a26228ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00003.safetensors:   0%|          | 0.00/4.55G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "256791d3f9f74aba95d9ac067c5fa257",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03e32e5f028f4f3dbe46380ae34b6a0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d47e922ebf4e482689f792417a0da63a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/141k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7cb4b2a54564b369905c8248a37d8c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/587k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fe50621882b4d5f8426bc8113b7f030",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20632d8e661647efb651f3bb548af866",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n",
      "<ipython-input-7-fe8f426a46f9>:69: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFacePipeline``.\n",
      "  llm = HuggingFacePipeline(pipeline=pipe)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "import pandas as pd\n",
    "import faiss\n",
    "import torch\n",
    "import numpy as np\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from transformers import pipeline\n",
    "from huggingface_hub import login\n",
    "\n",
    "login(token=\"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\")\n",
    "\n",
    "\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Define paths\n",
    "output_dir = \"/kaggle/working/\"\n",
    "text_file_path = os.path.join(output_dir, \"combined_document_10.txt\")\n",
    "\n",
    "# 1. Load extracted text\n",
    "with open(text_file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    extracted_text = file.read()\n",
    "\n",
    "# 2. Load extracted table data from CSVs and convert to text\n",
    "table_texts = []\n",
    "for filename in os.listdir(output_dir):\n",
    "    if filename.startswith(\"combined_document_10_table_\") and filename.endswith(\".csv\"):\n",
    "        csv_path = os.path.join(output_dir, filename)\n",
    "        try:\n",
    "            df = pd.read_csv(csv_path)\n",
    "            table_text = f\"Table: {filename}\\n\" + df.to_string(index=False) + \"\\n\"\n",
    "            table_texts.append(table_text)\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error reading {csv_path}: {e}\")\n",
    "\n",
    "# Combine extracted text and table data\n",
    "full_text = extracted_text + \"\\n\\n\" + \"\\n\\n\".join(table_texts)\n",
    "\n",
    "# 3. Initialize HuggingFace Embeddings (use GPU if available)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\", model_kwargs={\"device\": device})\n",
    "\n",
    "# 4. Split the text and tables into smaller chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
    "text_chunks = text_splitter.split_text(full_text)\n",
    "\n",
    "# 5. Create FAISS index from combined text & tables\n",
    "faiss_index_path = os.path.join(output_dir, \"faiss_index\")\n",
    "vector_store = FAISS.from_texts(text_chunks, embedding_model)\n",
    "vector_store.save_local(faiss_index_path)\n",
    "\n",
    "\n",
    "vector_store = FAISS.load_local(faiss_index_path, embedding_model, allow_dangerous_deserialization=True)\n",
    "\n",
    "# 7. Load LLM (LLaMA-2 or similar)\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=\"mistralai/Mistral-7B-Instruct-v0.3\",\n",
    "    model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "    device=\"cuda\",  \n",
    ")\n",
    "\n",
    "# Wrap the pipeline for LangChain\n",
    "llm = HuggingFacePipeline(pipeline=pipe)\n",
    "\n",
    "\n",
    "# 8. Build Retrieval-Augmented Generation (RAG) Pipeline\n",
    "qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=vector_store.as_retriever())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRYING OUT QUERIES:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T08:15:00.555135Z",
     "iopub.status.busy": "2025-03-11T08:15:00.554841Z",
     "iopub.status.idle": "2025-03-11T08:16:15.638702Z",
     "shell.execute_reply": "2025-03-11T08:16:15.637824Z",
     "shell.execute_reply.started": "2025-03-11T08:15:00.555112Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helpful Answer: In fiscal year 2018, Apple spent $11,988 million on\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helpful Answer: The total iPhone sales figures (in units) for Apple in 2018 were 2\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helpful Answer: Microsoft repurchased 148 million shares in fiscal year 2016, and\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helpful Answer: In 2018, Apple's net sales for the Americas region were $1\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helpful Answer: Microsoft acquired LinkedIn Corporation on December 8, 2016.\n",
      "\n",
      "Full Answer\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helpful Answer: The dividend per share declared by Microsoft in September 2015 was $0.3\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helpful Answer: The increase in iPad net sales during 2018 compared to 2017 was\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helpful Answer: In 2018, Apple's Services segment contributed $37,190\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helpful Answer: The main components of Microsoft's 'Other Income (Expense), Net' for fiscal year\n",
      "--------------------------------------------------------------------------------\n",
      "Helpful Answer: The anticipated gross margin percentage range for the first quarter of 2019 is between 3\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "queries = [\n",
    "    # 1. Apple's R&D Spending (2018 vs. 2017)\n",
    "    \"How much did Apple spend on Research and Development in fiscal year 2018, and how did it change compared to 2017?\",\n",
    "\n",
    "    # 2. iPhone Sales (Units) in 2018 vs. 2017\n",
    "    \"What were the total iPhone sales figures (in units) for Apple in 2018, and how did this compare to the previous year?\",\n",
    "\n",
    "    # 3. Microsoft Share Repurchase (2016)\n",
    "    \"How many shares did Microsoft repurchase in fiscal year 2016, and what was the total amount spent?\",\n",
    "\n",
    "    # 4. Apple's Net Sales in Americas (2018)\n",
    "    \"What was Apple's net sales figure for the Americas region in 2018, and what percentage of total net sales did this represent?\",\n",
    "\n",
    "    # 5. Microsoft's LinkedIn Acquisition Date\n",
    "    \"When did Microsoft acquire LinkedIn Corporation according to the quarterly information?\",\n",
    "\n",
    "    # 6. Microsoft's Dividend per Share (September 2015)\n",
    "    \"What was the dividend per share declared by Microsoft in September 2015?\",\n",
    "\n",
    "    # 7. Factors for iPad Sales Increase (2018 vs. 2017)\n",
    "    \"What factors contributed to the increase in iPad net sales during 2018 compared to 2017?\",\n",
    "\n",
    "    # 8. Apple's Services Segment Contribution (2018)\n",
    "    \"How much did Apple's Services segment contribute to total net sales in 2018, and what was the year-over-year growth percentage?\",\n",
    "\n",
    "    # 9. Components of Microsoft's 'Other Income (Expense), Net' (2018)\n",
    "    \"What were the main components of Microsoft's 'Other Income (Expense), Net' for fiscal year 2018?\",\n",
    "\n",
    "    # 10. Apple's Gross Margin Projection (Q1 2019)\n",
    "    \"What was Apple's gross margin percentage range anticipated for the first quarter of 2019?\"\n",
    "]\n",
    "\n",
    "for q in queries:\n",
    "    response = qa_chain.run(q)\n",
    "    ans = response.find(\"Helpful Answer\")\n",
    "    print(response[ans:])\n",
    "    print(\"-\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6839781,
     "sourceId": 10989223,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
